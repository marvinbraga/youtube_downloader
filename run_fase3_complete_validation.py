#!/usr/bin/env python3
"""
FASE 3 - Complete Validation Runner
Script master para executar toda a validaÃ§Ã£o da FASE 3

Agent-QualityAssurance - ExecuÃ§Ã£o completa da validaÃ§Ã£o
Executa todos os testes implementados e gera relatÃ³rio final
"""

import asyncio
import sys
import os
from pathlib import Path

# Adicionar pasta tests ao path
current_dir = Path(__file__).parent
tests_dir = current_dir / "tests"
sys.path.insert(0, str(tests_dir))

from reports.fase3_validation_report import FASE3ValidationReportGenerator

from loguru import logger

# Configurar logger
logger.remove()
logger.add(sys.stdout, format="<green>{time:HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{message}</cyan>")


def print_header():
    """Imprime cabeÃ§alho da validaÃ§Ã£o"""
    print("=" * 100)
    print("ğŸ† FASE 3 - COMPLETE VALIDATION SUITE")
    print("Agent-QualityAssurance - YouTube Downloader FASE 3 Validation")
    print("=" * 100)
    print("")
    print("ğŸ“‹ VALIDATION COMPONENTS:")
    print("  ğŸ§ª Integration Tests - API endpoints Redis vs JSON")
    print("  âš¡ Performance Benchmarks - Latency and throughput validation")
    print("  ğŸ”¥ Load & Stress Tests - 1000+ connections, high concurrency")
    print("  ğŸ”„ End-to-End Scenarios - Complete workflow validation") 
    print("  ğŸ“Š Final Report - Approval/rejection with detailed metrics")
    print("")
    print("ğŸ¯ APPROVAL CRITERIA:")
    print("  âœ… Integration Tests: â‰¥95% success rate")
    print("  âœ… Performance Benchmarks: All critical targets met")
    print("  âœ… Load Tests: â‰¥90% success under load")
    print("  âœ… E2E Scenarios: â‰¥80% working")
    print("  âœ… Zero critical blocking issues")
    print("")
    print("ğŸš€ Starting validation in 3 seconds...")
    print("=" * 100)


async def main():
    """FunÃ§Ã£o principal"""
    print_header()
    
    # Aguardar antes de iniciar
    await asyncio.sleep(3)
    
    try:
        # Inicializar gerador de relatÃ³rio
        report_generator = FASE3ValidationReportGenerator()
        
        # Executar validaÃ§Ã£o completa
        logger.info("ğŸš€ Starting FASE 3 Complete Validation...")
        validation_result = await report_generator.generate_complete_validation_report()
        
        print("")
        print("=" * 100)
        print("ğŸ FASE 3 VALIDATION COMPLETED")
        print("=" * 100)
        
        # Determinar resultado final
        if validation_result.overall_status == "APPROVED":
            logger.success("ğŸ‰ RESULTADO: FASE 3 APROVADA PARA PRODUÃ‡ÃƒO!")
            logger.success("âœ… Todos os critÃ©rios crÃ­ticos atendidos")
            logger.success("âœ… Sistema pronto para deployment")
            logger.success("âœ… Performance targets atingidos")
            logger.success("âœ… Escalabilidade validada")
            logger.success("âœ… Integridade de dados confirmada")
            print("")
            print("ğŸ“‹ PRÃ“XIMOS PASSOS:")
            print("  1. Proceder com cutover para produÃ§Ã£o")
            print("  2. Monitorar mÃ©tricas pÃ³s-deployment")
            print("  3. Agendar review em 1 semana")
            return 0
            
        elif validation_result.overall_status == "CONDITIONAL":
            logger.warning("âš ï¸ RESULTADO: FASE 3 APROVAÃ‡ÃƒO CONDICIONAL")
            logger.warning("ğŸ” Deployment com monitoramento reforÃ§ado")
            logger.warning("â° Re-validaÃ§Ã£o necessÃ¡ria em 72h")
            print("")
            print("ğŸ“‹ PRÃ“XIMOS PASSOS:")
            print("  1. Corrigir issues nÃ£o-crÃ­ticos identificados")
            print("  2. Deployment gradual com monitoramento")
            print("  3. Re-validaÃ§Ã£o obrigatÃ³ria")
            return 2
            
        else:
            logger.error("âŒ RESULTADO: FASE 3 REPROVADA")
            logger.error("ğŸš¨ Issues crÃ­ticos impedem deployment")
            logger.error("ğŸ”§ CorreÃ§Ãµes obrigatÃ³rias necessÃ¡rias")
            print("")
            print("ğŸ“‹ PRÃ“XIMOS PASSOS:")
            print("  1. Corrigir TODOS os issues crÃ­ticos")
            print("  2. Executar nova validaÃ§Ã£o completa")
            print("  3. NÃ£o proceder com deployment")
            return 1
            
    except KeyboardInterrupt:
        logger.warning("âš ï¸ ValidaÃ§Ã£o interrompida pelo usuÃ¡rio")
        return 130
        
    except Exception as e:
        logger.error(f"ğŸ’¥ Erro crÃ­tico na validaÃ§Ã£o: {e}")
        logger.error("ğŸš¨ ValidaÃ§Ã£o falhou - investigar imediatamente")
        return 1


def check_environment():
    """Verifica se o ambiente estÃ¡ pronto para os testes"""
    logger.info("ğŸ” Checking test environment...")
    
    # Verificar estrutura de pastas
    required_dirs = [
        tests_dir / "integration",
        tests_dir / "performance", 
        tests_dir / "load",
        tests_dir / "scenarios",
        tests_dir / "reports"
    ]
    
    for dir_path in required_dirs:
        if not dir_path.exists():
            logger.error(f"âŒ Required directory missing: {dir_path}")
            return False
    
    # Verificar arquivos de teste principais
    required_files = [
        tests_dir / "integration" / "test_fase3_complete_integration.py",
        tests_dir / "performance" / "test_fase3_benchmarks.py",
        tests_dir / "load" / "test_fase3_load_stress.py", 
        tests_dir / "scenarios" / "test_fase3_end_to_end.py",
        tests_dir / "reports" / "fase3_validation_report.py"
    ]
    
    for file_path in required_files:
        if not file_path.exists():
            logger.error(f"âŒ Required test file missing: {file_path}")
            return False
    
    logger.success("âœ… Test environment verified")
    return True


if __name__ == "__main__":
    # Verificar ambiente antes de iniciar
    if not check_environment():
        logger.error("âŒ Environment check failed - cannot proceed")
        sys.exit(1)
    
    # Executar validaÃ§Ã£o
    exit_code = asyncio.run(main())
    sys.exit(exit_code)