"""
Script de Verifica√ß√£o de Integridade de Dados Migrados
Valida 100% da integridade entre dados JSON originais e Redis

Autor: Claude Code Agent
Data: 2025-08-26
Vers√£o: 1.0.0 - FASE 2 Data Integrity Verification
"""

import asyncio
import hashlib
import json
import os
import time
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple, Set

import redis.asyncio as redis
from loguru import logger

# Importar componentes do sistema
import sys
sys.path.append(str(Path(__file__).parent.parent))

from app.services.redis_connection import get_redis_client, init_redis
from app.services.redis_audio_manager import RedisAudioManager
from app.services.redis_video_manager import RedisVideoManager


class DataIntegrityVerifier:
    """
    Verificador completo de integridade de dados
    Garante 100% de correspond√™ncia entre JSON e Redis
    """
    
    def __init__(self, data_dir: str = "E:\\python\\youtube_downloader\\data"):
        self.data_dir = Path(data_dir)
        
        # Componentes Redis
        self.redis_client: Optional[redis.Redis] = None
        self.audio_manager: Optional[RedisAudioManager] = None
        self.video_manager: Optional[RedisVideoManager] = None
        
        # Estado da verifica√ß√£o
        self.verification_id = datetime.now(timezone.utc).strftime("%Y%m%d_%H%M%S")
        self.verification_results = {
            'verification_id': self.verification_id,
            'start_time': None,
            'end_time': None,
            'total_checks': 0,
            'passed_checks': 0,
            'failed_checks': 0,
            'warnings': 0,
            'detailed_results': {
                'audio_verification': {},
                'video_verification': {},
                'structural_verification': {},
                'data_consistency': {},
                'performance_metrics': {}
            },
            'integrity_score': 0.0,
            'recommendation': 'pending'
        }
        
        # Configura√ß√£o de logs
        self._setup_verification_logging()
        
        logger.info(f"üîç Verificador de Integridade inicializado: {self.verification_id}")
    
    def _setup_verification_logging(self):
        """Configura sistema de logs para verifica√ß√£o"""
        log_dir = Path("E:\\python\\youtube_downloader\\logs\\verification")
        log_dir.mkdir(parents=True, exist_ok=True)
        
        log_file = log_dir / f"verification_{self.verification_id}.log"
        
        logger.add(
            str(log_file),
            format="{time:YYYY-MM-DD HH:mm:ss.SSS} | {level} | {name}:{function}:{line} | {message}",
            level="DEBUG",
            retention="30 days"
        )
        
        logger.info(f"üìã Logs de verifica√ß√£o: {log_file}")
    
    async def execute_full_verification(self) -> Dict[str, Any]:
        """
        Executa verifica√ß√£o completa de integridade
        
        Returns:
            Resultado detalhado da verifica√ß√£o
        """
        logger.info("üöÄ Iniciando verifica√ß√£o completa de integridade")
        self.verification_results['start_time'] = time.time()
        
        try:
            # Inicializar Redis
            await self._initialize_redis_connection()
            
            # Verifica√ß√£o estrutural
            await self._verify_structural_integrity()
            
            # Verifica√ß√£o de dados de √°udios
            await self._verify_audio_data_integrity()
            
            # Verifica√ß√£o de dados de v√≠deos
            await self._verify_video_data_integrity()
            
            # Verifica√ß√£o de consist√™ncia
            await self._verify_data_consistency()
            
            # Verifica√ß√£o de performance
            await self._verify_performance_metrics()
            
            # Calcular score de integridade
            await self._calculate_integrity_score()
            
            # Gerar recomenda√ß√µes
            await self._generate_recommendations()
            
            self.verification_results['end_time'] = time.time()
            
            # Salvar relat√≥rio
            report = await self._generate_verification_report()
            
            logger.success("‚úÖ Verifica√ß√£o de integridade conclu√≠da")
            return report
            
        except Exception as e:
            logger.error(f"‚ùå Erro na verifica√ß√£o de integridade: {e}")
            self.verification_results['end_time'] = time.time()
            
            return {
                'success': False,
                'error': str(e),
                'verification_id': self.verification_id,
                'verification_results': self.verification_results
            }
    
    async def _initialize_redis_connection(self):
        """Inicializa conex√£o Redis para verifica√ß√£o"""
        logger.info("üîå Inicializando conex√£o Redis...")
        
        try:
            await init_redis()
            self.redis_client = await get_redis_client()
            await self.redis_client.ping()
            
            self.audio_manager = RedisAudioManager()
            self.video_manager = RedisVideoManager()
            
            await self.audio_manager.initialize()
            await self.video_manager.initialize()
            
            logger.success("‚úÖ Conex√£o Redis estabelecida")
            
        except Exception as e:
            logger.error(f"‚ùå Falha na conex√£o Redis: {e}")
            raise
    
    async def _verify_structural_integrity(self):
        """Verifica integridade estrutural dos dados"""
        logger.info("üèóÔ∏è Verificando integridade estrutural...")
        
        structural_results = {
            'redis_connection': False,
            'json_files_exist': False,
            'redis_keys_exist': False,
            'schema_validation': False,
            'errors': []
        }
        
        try:
            # Testar conex√£o Redis
            await self.redis_client.ping()
            structural_results['redis_connection'] = True
            self.verification_results['passed_checks'] += 1
            
        except Exception as e:
            structural_results['errors'].append(f"Redis connection failed: {e}")
            self.verification_results['failed_checks'] += 1
        
        # Verificar arquivos JSON
        audios_file = self.data_dir / 'audios.json'
        videos_file = self.data_dir / 'videos.json'
        
        if audios_file.exists() and videos_file.exists():
            structural_results['json_files_exist'] = True
            self.verification_results['passed_checks'] += 1
        else:
            structural_results['errors'].append("JSON files not found")
            self.verification_results['failed_checks'] += 1
        
        # Verificar chaves Redis
        try:
            redis_keys = await self.redis_client.keys("youtube_downloader:*")
            if len(redis_keys) > 0:
                structural_results['redis_keys_exist'] = True
                self.verification_results['passed_checks'] += 1
                logger.info(f"üìä Encontradas {len(redis_keys)} chaves Redis")
            else:
                structural_results['errors'].append("No Redis keys found")
                self.verification_results['failed_checks'] += 1
                
        except Exception as e:
            structural_results['errors'].append(f"Redis keys check failed: {e}")
            self.verification_results['failed_checks'] += 1
        
        # Valida√ß√£o de schema b√°sica
        try:
            if audios_file.exists():
                with open(audios_file, 'r', encoding='utf-8') as f:
                    audios_data = json.load(f)
                
                if 'audios' in audios_data and isinstance(audios_data['audios'], list):
                    structural_results['schema_validation'] = True
                    self.verification_results['passed_checks'] += 1
                else:
                    structural_results['errors'].append("Invalid JSON schema for audios")
                    self.verification_results['failed_checks'] += 1
                    
        except Exception as e:
            structural_results['errors'].append(f"Schema validation failed: {e}")
            self.verification_results['failed_checks'] += 1
        
        self.verification_results['total_checks'] += 4
        self.verification_results['detailed_results']['structural_verification'] = structural_results
        
        logger.info(f"üèóÔ∏è Verifica√ß√£o estrutural: {sum(1 for k, v in structural_results.items() if isinstance(v, bool) and v)}/4 passou")
    
    async def _verify_audio_data_integrity(self):
        """Verifica integridade completa dos dados de √°udios"""
        logger.info("üéµ Verificando integridade dos dados de √°udios...")
        
        audio_results = {
            'total_json_records': 0,
            'total_redis_records': 0,
            'matched_records': 0,
            'missing_in_redis': [],
            'missing_in_json': [],
            'data_mismatches': [],
            'field_mismatches': {},
            'integrity_score': 0.0
        }
        
        try:
            # Carregar dados JSON
            audios_file = self.data_dir / 'audios.json'
            if not audios_file.exists():
                audio_results['errors'] = ['audios.json not found']
                self.verification_results['detailed_results']['audio_verification'] = audio_results
                return
            
            with open(audios_file, 'r', encoding='utf-8') as f:
                json_data = json.load(f)
            
            json_audios = json_data.get('audios', [])
            audio_results['total_json_records'] = len(json_audios)
            
            # Obter dados Redis
            redis_audio_ids = await self.audio_manager.get_all_audio_ids()
            audio_results['total_redis_records'] = len(redis_audio_ids)
            
            logger.info(f"üìä JSON: {audio_results['total_json_records']} √°udios, Redis: {audio_results['total_redis_records']} √°udios")
            
            # Criar sets para compara√ß√£o
            json_ids = {audio['id'] for audio in json_audios}
            redis_ids = set(redis_audio_ids)
            
            # Encontrar IDs faltantes
            audio_results['missing_in_redis'] = list(json_ids - redis_ids)
            audio_results['missing_in_json'] = list(redis_ids - json_ids)
            
            if audio_results['missing_in_redis']:
                logger.warning(f"‚ö†Ô∏è {len(audio_results['missing_in_redis'])} √°udios ausentes no Redis")
                self.verification_results['warnings'] += 1
            
            if audio_results['missing_in_json']:
                logger.warning(f"‚ö†Ô∏è {len(audio_results['missing_in_json'])} √°udios ausentes no JSON")
                self.verification_results['warnings'] += 1
            
            # Verifica√ß√£o detalhada registro por registro
            matched_count = 0
            field_mismatch_counts = {}
            
            for json_audio in json_audios:
                audio_id = json_audio['id']
                
                if audio_id in redis_ids:
                    # Buscar dados no Redis
                    redis_audio = await self.audio_manager.get_audio(audio_id)
                    
                    if redis_audio:
                        # Comparar dados
                        mismatch_details = self._compare_audio_records(json_audio, redis_audio)
                        
                        if not mismatch_details['has_mismatches']:
                            matched_count += 1
                        else:
                            audio_results['data_mismatches'].append({
                                'audio_id': audio_id,
                                'mismatches': mismatch_details['mismatches']
                            })
                            
                            # Contar tipos de mismatches
                            for field in mismatch_details['mismatched_fields']:
                                field_mismatch_counts[field] = field_mismatch_counts.get(field, 0) + 1
                    else:
                        audio_results['missing_in_redis'].append(audio_id)
            
            audio_results['matched_records'] = matched_count
            audio_results['field_mismatches'] = field_mismatch_counts
            
            # Calcular score de integridade
            if audio_results['total_json_records'] > 0:
                audio_results['integrity_score'] = (matched_count / audio_results['total_json_records']) * 100
            
            # Atualizar contadores globais
            self.verification_results['total_checks'] += audio_results['total_json_records']
            self.verification_results['passed_checks'] += matched_count
            self.verification_results['failed_checks'] += (audio_results['total_json_records'] - matched_count)
            
            logger.info(f"üéµ √Åudios verificados: {matched_count}/{audio_results['total_json_records']} ({audio_results['integrity_score']:.1f}%)")
            
        except Exception as e:
            logger.error(f"‚ùå Erro na verifica√ß√£o de √°udios: {e}")
            audio_results['errors'] = [str(e)]
            self.verification_results['failed_checks'] += 1
        
        self.verification_results['detailed_results']['audio_verification'] = audio_results
    
    def _compare_audio_records(self, json_record: Dict, redis_record: Dict) -> Dict[str, Any]:
        """Compara detalhadamente registros de √°udio"""
        mismatches = []
        mismatched_fields = []
        
        # Campos cr√≠ticos para compara√ß√£o
        critical_fields = ['id', 'title', 'youtube_id', 'url', 'format', 'filesize']
        
        for field in critical_fields:
            json_value = json_record.get(field)
            redis_value = redis_record.get(field)
            
            # Normalizar valores para compara√ß√£o
            if isinstance(json_value, (int, float)) and isinstance(redis_value, str):
                try:
                    redis_value = type(json_value)(redis_value)
                except (ValueError, TypeError):
                    pass
            
            if json_value != redis_value:
                mismatches.append({
                    'field': field,
                    'json_value': json_value,
                    'redis_value': redis_value,
                    'type_json': type(json_value).__name__,
                    'type_redis': type(redis_value).__name__
                })
                mismatched_fields.append(field)
        
        # Verifica√ß√£o especial para keywords (podem ser em ordens diferentes)
        json_keywords = set(json_record.get('keywords', []))
        redis_keywords = set(redis_record.get('keywords', []))
        
        if json_keywords != redis_keywords:
            mismatches.append({
                'field': 'keywords',
                'json_value': list(json_keywords),
                'redis_value': list(redis_keywords),
                'missing_in_redis': list(json_keywords - redis_keywords),
                'extra_in_redis': list(redis_keywords - json_keywords)
            })
            mismatched_fields.append('keywords')
        
        return {
            'has_mismatches': len(mismatches) > 0,
            'mismatch_count': len(mismatches),
            'mismatches': mismatches,
            'mismatched_fields': mismatched_fields
        }
    
    async def _verify_video_data_integrity(self):
        """Verifica integridade dos dados de v√≠deos"""
        logger.info("üé¨ Verificando integridade dos dados de v√≠deos...")
        
        video_results = {
            'total_json_records': 0,
            'total_redis_records': 0,
            'matched_records': 0,
            'data_mismatches': [],
            'integrity_score': 0.0
        }
        
        try:
            # Carregar dados JSON
            videos_file = self.data_dir / 'videos.json'
            if not videos_file.exists():
                video_results['errors'] = ['videos.json not found']
                self.verification_results['detailed_results']['video_verification'] = video_results
                return
            
            with open(videos_file, 'r', encoding='utf-8') as f:
                json_data = json.load(f)
            
            json_videos = json_data.get('videos', [])
            video_results['total_json_records'] = len(json_videos)
            
            # Obter contagem Redis
            redis_video_count = await self.video_manager.get_total_count()
            video_results['total_redis_records'] = redis_video_count
            
            # Verifica√ß√£o registro por registro
            matched_count = 0
            
            for json_video in json_videos:
                video_name = json_video.get('name')
                if not video_name:
                    continue
                
                # Buscar no Redis
                redis_video = await self.video_manager.get_video(video_name)
                
                if redis_video:
                    # Comparar dados b√°sicos
                    if (json_video.get('path') == redis_video.get('path') and
                        json_video.get('type') == redis_video.get('type')):
                        matched_count += 1
                    else:
                        video_results['data_mismatches'].append({
                            'video_name': video_name,
                            'json_data': json_video,
                            'redis_data': redis_video
                        })
                else:
                    video_results['data_mismatches'].append({
                        'video_name': video_name,
                        'error': 'not_found_in_redis'
                    })
            
            video_results['matched_records'] = matched_count
            
            if video_results['total_json_records'] > 0:
                video_results['integrity_score'] = (matched_count / video_results['total_json_records']) * 100
            
            # Atualizar contadores globais
            self.verification_results['total_checks'] += video_results['total_json_records']
            self.verification_results['passed_checks'] += matched_count
            self.verification_results['failed_checks'] += (video_results['total_json_records'] - matched_count)
            
            logger.info(f"üé¨ V√≠deos verificados: {matched_count}/{video_results['total_json_records']} ({video_results['integrity_score']:.1f}%)")
            
        except Exception as e:
            logger.error(f"‚ùå Erro na verifica√ß√£o de v√≠deos: {e}")
            video_results['errors'] = [str(e)]
            self.verification_results['failed_checks'] += 1
        
        self.verification_results['detailed_results']['video_verification'] = video_results
    
    async def _verify_data_consistency(self):
        """Verifica consist√™ncia geral dos dados"""
        logger.info("üîó Verificando consist√™ncia dos dados...")
        
        consistency_results = {
            'duplicate_checks': {},
            'referential_integrity': {},
            'data_types_consistency': {},
            'encoding_issues': []
        }
        
        # Verificar duplicatas no Redis
        audio_ids = await self.audio_manager.get_all_audio_ids()
        duplicate_ids = []
        seen_ids = set()
        
        for audio_id in audio_ids:
            if audio_id in seen_ids:
                duplicate_ids.append(audio_id)
            else:
                seen_ids.add(audio_id)
        
        consistency_results['duplicate_checks'] = {
            'total_audio_ids': len(audio_ids),
            'unique_audio_ids': len(seen_ids),
            'duplicates_found': len(duplicate_ids),
            'duplicate_ids': duplicate_ids
        }
        
        if len(duplicate_ids) > 0:
            logger.warning(f"‚ö†Ô∏è {len(duplicate_ids)} IDs duplicados encontrados")
            self.verification_results['warnings'] += 1
        else:
            self.verification_results['passed_checks'] += 1
        
        self.verification_results['total_checks'] += 1
        self.verification_results['detailed_results']['data_consistency'] = consistency_results
    
    async def _verify_performance_metrics(self):
        """Verifica m√©tricas de performance do Redis"""
        logger.info("‚ö° Verificando m√©tricas de performance...")
        
        performance_results = {
            'connection_latency': 0.0,
            'read_latency': 0.0,
            'memory_usage': {},
            'key_counts': {}
        }
        
        try:
            # Testar lat√™ncia de conex√£o
            start_time = time.time()
            await self.redis_client.ping()
            performance_results['connection_latency'] = (time.time() - start_time) * 1000  # ms
            
            # Testar lat√™ncia de leitura
            audio_ids = await self.audio_manager.get_all_audio_ids()
            if audio_ids:
                sample_id = audio_ids[0]
                start_time = time.time()
                await self.audio_manager.get_audio(sample_id)
                performance_results['read_latency'] = (time.time() - start_time) * 1000  # ms
            
            # Informa√ß√µes de mem√≥ria
            info = await self.redis_client.info()
            performance_results['memory_usage'] = {
                'used_memory': info.get('used_memory', 0),
                'used_memory_human': info.get('used_memory_human', '0B'),
                'used_memory_peak': info.get('used_memory_peak', 0),
                'used_memory_peak_human': info.get('used_memory_peak_human', '0B')
            }
            
            # Contagem de chaves
            all_keys = await self.redis_client.keys("youtube_downloader:*")
            audio_keys = [k for k in all_keys if b'audio:' in k]
            video_keys = [k for k in all_keys if b'video:' in k]
            
            performance_results['key_counts'] = {
                'total_keys': len(all_keys),
                'audio_keys': len(audio_keys),
                'video_keys': len(video_keys)
            }
            
            logger.info(f"‚ö° Lat√™ncia: {performance_results['connection_latency']:.2f}ms (ping), {performance_results['read_latency']:.2f}ms (read)")
            logger.info(f"‚ö° Mem√≥ria: {performance_results['memory_usage']['used_memory_human']}")
            
            self.verification_results['passed_checks'] += 1
            
        except Exception as e:
            logger.error(f"‚ùå Erro na verifica√ß√£o de performance: {e}")
            performance_results['errors'] = [str(e)]
            self.verification_results['failed_checks'] += 1
        
        self.verification_results['total_checks'] += 1
        self.verification_results['detailed_results']['performance_metrics'] = performance_results
    
    async def _calculate_integrity_score(self):
        """Calcula score geral de integridade"""
        logger.info("üìä Calculando score de integridade...")
        
        if self.verification_results['total_checks'] > 0:
            score = (self.verification_results['passed_checks'] / self.verification_results['total_checks']) * 100
            self.verification_results['integrity_score'] = round(score, 2)
        else:
            self.verification_results['integrity_score'] = 0.0
        
        logger.info(f"üìä Score de Integridade: {self.verification_results['integrity_score']:.1f}%")
    
    async def _generate_recommendations(self):
        """Gera recomenda√ß√µes baseadas nos resultados"""
        score = self.verification_results['integrity_score']
        failed_checks = self.verification_results['failed_checks']
        warnings = self.verification_results['warnings']
        
        if score >= 98.0 and failed_checks == 0:
            recommendation = "EXCELLENT - Migra√ß√£o perfeita, sistema pronto para produ√ß√£o"
        elif score >= 95.0 and failed_checks <= 2:
            recommendation = "GOOD - Migra√ß√£o bem-sucedida com problemas menores, monitorar"
        elif score >= 90.0 and failed_checks <= 5:
            recommendation = "ACCEPTABLE - Migra√ß√£o aceit√°vel, corrigir problemas identificados"
        elif score >= 80.0:
            recommendation = "NEEDS_ATTENTION - Problemas significativos, investiga√ß√£o necess√°ria"
        else:
            recommendation = "CRITICAL - Falhas graves, rollback recomendado"
        
        self.verification_results['recommendation'] = recommendation
        logger.info(f"üí° Recomenda√ß√£o: {recommendation}")
    
    async def _generate_verification_report(self) -> Dict[str, Any]:
        """Gera relat√≥rio completo da verifica√ß√£o"""
        duration = self.verification_results['end_time'] - self.verification_results['start_time']
        
        report = {
            'success': True,
            'verification_id': self.verification_id,
            'timestamp': datetime.now(timezone.utc).isoformat(),
            'duration_seconds': round(duration, 2),
            'integrity_score': self.verification_results['integrity_score'],
            'recommendation': self.verification_results['recommendation'],
            'summary': {
                'total_checks': self.verification_results['total_checks'],
                'passed_checks': self.verification_results['passed_checks'],
                'failed_checks': self.verification_results['failed_checks'],
                'warnings': self.verification_results['warnings'],
                'pass_rate': round(
                    (self.verification_results['passed_checks'] / max(1, self.verification_results['total_checks'])) * 100, 2
                )
            },
            'detailed_results': self.verification_results['detailed_results'],
            'verification_results': self.verification_results
        }
        
        # Salvar relat√≥rio
        report_dir = Path("E:\\python\\youtube_downloader\\reports\\verification")
        report_dir.mkdir(parents=True, exist_ok=True)
        
        report_file = report_dir / f"integrity_verification_{self.verification_id}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False, default=str)
        
        logger.success(f"üìä Relat√≥rio de verifica√ß√£o salvo: {report_file}")
        
        return report


# Fun√ß√£o principal para execu√ß√£o
async def verify_data_integrity() -> Dict[str, Any]:
    """
    Executa verifica√ß√£o completa de integridade dos dados
    
    Returns:
        Resultado da verifica√ß√£o
    """
    verifier = DataIntegrityVerifier()
    return await verifier.execute_full_verification()


if __name__ == "__main__":
    # Exemplo de uso
    async def main():
        result = await verify_data_integrity()
        
        if result['success']:
            print(f"‚úÖ Verifica√ß√£o conclu√≠da!")
            print(f"üìä Score de Integridade: {result['integrity_score']:.1f}%")
            print(f"üîç Checks: {result['summary']['passed_checks']}/{result['summary']['total_checks']} passou")
            print(f"üí° Recomenda√ß√£o: {result['recommendation']}")
            
            if result['summary']['failed_checks'] > 0:
                print(f"‚ö†Ô∏è Falhas encontradas: {result['summary']['failed_checks']}")
            
            if result['summary']['warnings'] > 0:
                print(f"‚ö†Ô∏è Avisos: {result['summary']['warnings']}")
        else:
            print(f"‚ùå Verifica√ß√£o falhou: {result.get('error')}")
    
    asyncio.run(main())